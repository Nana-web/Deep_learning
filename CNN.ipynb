{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer, ConvolutionalLayer, MaxPoolingLayer, Flattener\n",
    "from model_conv import ConvNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):    \n",
    "    train_X = train_X.astype(np.float) / 255.0\n",
    "    test_X = test_X.astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_X, axis = 0)\n",
    "    train_X -= mean_image\n",
    "    test_X -= mean_image\n",
    "    \n",
    "    return train_X, test_X\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (2, 2, 2, 1)\n",
      "Shape of W (2, 2, 1, 1)\n",
      "Shape of X: (2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ConvolutionaLayer that supports only 1 output and input channel\n",
    "\n",
    "# Note: now you're working with images, so X is 4-dimensional tensor of\n",
    "# (batch_size, height, width, channels)\n",
    "\n",
    "X = np.array([\n",
    "              [\n",
    "               [[1.0], [2.0]],\n",
    "               [[0.0], [-1.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0], [1.0]],\n",
    "               [[-2.0], [-1.0]]\n",
    "              ]\n",
    "             ])\n",
    "\n",
    "# Batch of 2 images of dimensions 2x2 with a single channel\n",
    "print(\"Shape of X:\",X.shape)\n",
    "\n",
    "layer = ConvolutionalLayer(in_channels=1, out_channels=1, filter_size=2, padding=0)\n",
    "print(\"Shape of W\", layer.W.value.shape)\n",
    "layer.W.value = np.zeros_like(layer.W.value)\n",
    "layer.W.value[0, 0, 0, 0] = 1.0\n",
    "layer.B.value = np.ones_like(layer.B.value)\n",
    "result = layer.forward(X)\n",
    "\n",
    "assert result.shape == (2, 1, 1, 1)\n",
    "assert np.all(result == X[:, :1, :1, :1] +1), \"result: %s, X: %s\" % (result, X[:, :1, :1, :1])\n",
    "\n",
    "# Now let's implement multiple output channels\n",
    "layer = ConvolutionalLayer(in_channels=1, out_channels=2, filter_size=2, padding=0)\n",
    "result = layer.forward(X)\n",
    "assert result.shape == (2, 1, 1, 2)\n",
    "\n",
    "\n",
    "# And now multple input channels!\n",
    "X = np.array([\n",
    "              [\n",
    "               [[1.0, 0.0], [2.0, 1.0]],\n",
    "               [[0.0, -1.0], [-1.0, -2.0]]\n",
    "              ]\n",
    "              ,\n",
    "              [\n",
    "               [[0.0, 1.0], [1.0, -1.0]],\n",
    "               [[-2.0, 2.0], [-1.0, 0.0]]\n",
    "              ]\n",
    "             ])\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "result = layer.forward(X)\n",
    "assert result.shape == (2, 1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# First test - check the shape is right\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "result = layer.forward(X)\n",
    "d_input = layer.backward(np.ones_like(result))\n",
    "assert d_input.shape == X.shape\n",
    "\n",
    "# Actually test the backward pass\n",
    "# As usual, you'll need to copy gradient check code from the previous assignment\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "assert check_layer_gradient(layer, X)\n",
    "\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "assert check_layer_param_gradient(layer, X, 'W')\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
    "assert check_layer_param_gradient(layer, X, 'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=3, padding=1)\n",
    "result = layer.forward(X)\n",
    "# Note this kind of layer produces the same dimensions as input\n",
    "assert result.shape == X.shape,\"Result shape: %s - Expected shape %s\" % (result.shape, X.shape)\n",
    "d_input = layer.backward(np.ones_like(result))\n",
    "assert d_input.shape == X.shape\n",
    "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=3, padding=1)\n",
    "assert check_layer_gradient(layer, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "pool = MaxPoolingLayer(2, 2)\n",
    "result = pool.forward(X)\n",
    "assert result.shape == (2, 1, 1, 2)\n",
    "\n",
    "assert check_layer_gradient(pool, X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "flattener = Flattener()\n",
    "result = flattener.forward(X)\n",
    "assert result.shape == (2,8)\n",
    "\n",
    "assert check_layer_gradient(flattener, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n",
      "Checking gradient for W3\n",
      "Gradient check passed!\n",
      "Checking gradient for B3\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement missed functions function for ConvNet model\n",
    "\n",
    "# No need to use L2 regularization\n",
    "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302694, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302659, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302625, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302590, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302556, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302521, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302487, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302452, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302418, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302383, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302349, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302314, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302280, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302245, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302211, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302176, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302142, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302107, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302073, Train accuracy: 0.062500, val accuracy: 0.000000\n",
      "Loss: 2.302038, Train accuracy: 0.062500, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
    "dataset = Dataset(train_X[:16], train_y[:16], val_X[:16], val_y[:16])\n",
    "trainer = Trainer(model, dataset, SGD(), batch_size=16, learning_rate=1e-4)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x8cbe748>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.305242, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.287696, Train accuracy: 0.156250, val accuracy: 0.093750\n",
      "Loss: 2.287327, Train accuracy: 0.187500, val accuracy: 0.250000\n",
      "Loss: 2.337153, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.229412, Train accuracy: 0.156250, val accuracy: 0.093750\n",
      "Loss: 2.269440, Train accuracy: 0.203125, val accuracy: 0.242188\n",
      "Loss: 2.287129, Train accuracy: 0.187500, val accuracy: 0.226562\n",
      "Loss: 2.211274, Train accuracy: 0.148438, val accuracy: 0.062500\n",
      "Loss: 2.215230, Train accuracy: 0.187500, val accuracy: 0.250000\n",
      "Loss: 2.351107, Train accuracy: 0.195312, val accuracy: 0.218750\n",
      "Loss: 2.250535, Train accuracy: 0.179688, val accuracy: 0.125000\n",
      "Loss: 2.253449, Train accuracy: 0.195312, val accuracy: 0.210938\n",
      "Loss: 2.227093, Train accuracy: 0.171875, val accuracy: 0.250000\n",
      "Loss: 2.219715, Train accuracy: 0.187500, val accuracy: 0.109375\n",
      "Loss: 2.238069, Train accuracy: 0.242188, val accuracy: 0.218750\n",
      "Loss: 2.139072, Train accuracy: 0.195312, val accuracy: 0.242188\n",
      "Loss: 2.093861, Train accuracy: 0.210938, val accuracy: 0.148438\n",
      "Loss: 2.075627, Train accuracy: 0.296875, val accuracy: 0.171875\n",
      "Loss: 2.055799, Train accuracy: 0.210938, val accuracy: 0.250000\n",
      "Loss: 2.033499, Train accuracy: 0.226562, val accuracy: 0.250000\n"
     ]
    }
   ],
   "source": [
    "data_size = 128\n",
    "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=3, conv2_channels=3)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach 1.0 training accuracy in 50 epochs or less\n",
    "# Hint: If you have hard time finding the right parameters manually, try grid search or random search!\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, learning_rate_decay=1, num_epochs=20, batch_size=64)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.260800, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.175084, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.161721, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.227841, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.181467, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.266383, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.259553, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.202524, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.228290, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.196900, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.276017, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.232297, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.238008, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.238758, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.261645, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.169731, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.283344, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.192298, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.204512, Train accuracy: 0.179688, val accuracy: 0.250000\n",
      "Loss: 2.193033, Train accuracy: 0.179688, val accuracy: 0.250000\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, learning_rate_decay=1, num_epochs=20, batch_size=64)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
