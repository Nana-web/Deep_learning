{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement check_gradient function in gradient_check.py\n",
    "# All the functions below should pass the gradient check\n",
    "\n",
    "def square(x):\n",
    "    return float(x*x), 2*x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Implement softmax and cross-entropy for single sample\n",
    "probs = linear_classifer.softmax(np.array([-10, 0, 10]))\n",
    "\n",
    "# Make sure it works for big numbers too!\n",
    "probs = linear_classifer.softmax(np.array([1000, 0, 0]))\n",
    "assert np.isclose(probs[0], 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.006760443547122"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = linear_classifer.softmax(np.array([-5, 0, 5]))\n",
    "linear_classifer.cross_entropy_loss(probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement combined function or softmax and cross entropy and produces gradient\n",
    "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO Extend combined function so it can receive a 2d array with batch of samples\n",
    "np.random.seed(42)\n",
    "# Test batch_size = 1\n",
    "num_classes = 4\n",
    "batch_size = 1\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Test batch_size = 3\n",
    "num_classes = 4\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Make sure maximum subtraction for numberic stability is done separately for every sample in the batch\n",
    "probs = linear_classifer.softmax(np.array([[20,0,0], [1000, 0, 0]]))\n",
    "assert np.all(np.isclose(probs[:, 0], 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement linear_softmax function that uses softmax with cross-entropy for linear classifier\n",
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float)\n",
    "target_index = np.ones(batch_size, dtype=np.int)\n",
    "\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement l2_regularization function that implements loss for L2 regularization\n",
    "loss, dW = linear_classifer.l2_regularization(W, 0.01)\n",
    "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement LinearSoftmaxClassifier.fit function\n",
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=10, learning_rate=1e-3, batch_size=300, reg=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x5704630>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3iV9d3H8fc3mwxWSAgkZLBH2JEpKFZliDJqsVXRisKjpVXqrLbu2tr2qVafOoriqlYcDOsARKWiIGCYSQg7QAgJBMIICdnf548cbERGAknuM76v68p1He7zu8/5nAOcT869fqKqGGOM8T1+TgcwxhjjDCsAY4zxUVYAxhjjo6wAjDHGR1kBGGOMjwpwOkBdtGrVShMTE52OYYwxHmX16tUHVDXq5OUeVQCJiYmkpqY6HcMYYzyKiOw61XLbBGSMMT7KCsAYY3yUFYAxxvgoKwBjjPFRVgDGGOOjrACMMcZHWQEYY4yPsgJoJAePlfJuajarsgqcjmKMMYCHnQjmaXKPHGdReh4LM/JYlVVAlULTkACW3H0xkeHBTsczxvg4K4B6tvNAEQsz8liYnse67MMAdG4dzi9HdKRHbDOmv7WGvyzazJM/7uVwUmOMr7MCOE+qyuZ9hSxMr/7Q35RXCECvuGbcM7ILo5Jj6BAV/t34m4Ym8vLXWfx0QDx92jV3KrYxxlgBnAtVZf2eIyxIz2VReh47DxYjAhcktOShsd25vEdr4lqEnnLd23/Uifnr9vLwB+nM+8VQ/PykkdMbY0w1K4BaqqxSVmUVsCgjj0UZeeQeKSHATxjcIZJpwztwWffWREWcfbt+REggD4zpyq/fWc97q7O55oL4RkhvjDE/ZAVwBqUVlSzffpBF6Xks3riPg0VlBAf4cVHnKO4Z2YUfdW1Ns9DAOj/u+D6x/Gvlbv60cDOjerQ5p8cwxpjzZQVwkuKyCpZuyWdheh6fZ+6nsLSC8OAALukazajkGC7qHEVY8Pm9bSLCo1clM/b/vuKpxZt5dFxyPaU3xpjaswIAjhwv54tN+1iYnseXW/IpKa+iRWggo3vGMCo5hqEdWxEc4F+vz9m9bVMmD0rgnyt2MemCdvRo26xeH98YY87GZwvgwLFSFm+s/tBfvv0A5ZVK66bBTEppx6jkGAYktiTAv2HPk7vzsi58uCGXhz/I4L1bByNiO4SNMY3Hpwpg7+HjLHIdo//tzuoTs+JbhjJlaBIjk2PoE9e8UY/KaRYayH2junDfnDTmr8thQt+4RntuY4zxiQKYs3oPb6zYxfqaJ2Zd0olRPWLo1ibC0d+8f9K/Hf9auZs/fLKJS7u1JiLEdggbYxqHTxRA9qFiUOXeUV0Y2eP7J2Y5zc9PeGxcMuOfX8azn2/lt1d0dzqSMcZH+EQB3H5JJ2Zc2tnpGKfVu11zrklpx6vLdjIppR2dWkc4HckY4wN84mqgnnC27T0juxAa5M8jH2agqk7HMcb4AJ8oAE8QGR7M3SO7sGzbQRak5zkdxxjjA6wA3Mi1A+Lp1qYpv/9oI8VlFU7HMcZ4OSsANxLg78dj43qw90gJzy/Z7nQcY4yXswJwMxcktmRC31hmLt3BzgNFTscxxngxKwA3dP/orgQF+PGo7RA2xjQgKwA3FN00hBmXdmLJ5nw+z9zvdBxjjJeyAnBTNw5JpGN0OI9+lEFJeaXTcYwxXsgKwE0F+vvx6FU9yC44zsylO5yOY4zxQlYAbmxox1Zc0bMNzy3ZRnZBsdNxjDFexgrAzT1wRTf8RHji40ynoxhjvIwVgJuLbd6EX17SkYUZeSzdku90HGOMFzlrAYhIOxFZIiKZIpIhInecYsw4EdkgIutEJFVELqxx340istX1c2ON5f1FJE1EtonIs2KzoZzWLcOSSIwM5ZEPMyirqHI6jjHGS9TmG0AFcJeqdgMGAdNF5ORrFn8O9FbVPsAU4GUAEWkJPAwMBAYAD4tIC9c6LwDTgE6un1Hn+Vq8VnCAPw9f2YMd+UW8uizL6TjGGC9x1gJQ1VxVXeO6XQhkArEnjTmm/z1jKQw4cXsksFhVC1T1ELAYGCUibYCmqvqNa703gPH18oq81Iiu0VzaLZpnP99K3pESp+MYY7xAnfYBiEgi0BdYeYr7JojIJuBjqr8FQHVRZNcYtse1LNZ1++Tlp3rOaa7NSqn5+b69DfzBsd0pr1L+uMB2CBtjzl+tC0BEwoE5wAxVPXry/ao6T1W7Uv2b/OMnVjvFQ+kZlv9woepMVU1R1ZSoqKjaxvVKCZFh3Dq8PR+s28vKHQedjmOM8XC1KgARCaT6w/8tVZ17prGquhToICKtqP7Nvl2Nu+OAva7lcadYbs7itos7Etu8CQ//O4OKStshbIw5d7U5CkiAWUCmqj51mjEdTxzFIyL9gCDgILAIuFxEWrh2/l4OLFLVXKBQRAa51rsB+KBeXpGXaxLkz4Nju7Mpr5B/rtjldBxjjAerzZzAQ4HJQJqIrHMtewCIB1DVF4EfAzeISDlwHLjGtXO3QEQeB751rfeYqha4bt8GvAY0ARa4fkwtjOzRmmGdWvHUp1sY26stURHBTkcyxngg8aTLDaekpGhqaqrTMdzC9vxjjPrbUsb3ieUvP+ntdBxjjBsTkdWqmnLycjsT2EN1iApnyoVJvLd6D2t2H3I6jjHGA1kBeLBfXdKJ1k2DefiDDCqrPOebnDHGPVgBeLDw4AAeGNONtJwjvPNt9tlXMMaYGqwAPNxVvdsyIKklf160iUNFZU7HMcZ4ECsADyciPHpVDwpLKvjr4s1OxzHGeBArAC/QrU1TJg9K4K2Vu0nPOeJ0HGOMh7AC8BK/vqwzLUODeOiDdKpsh7AxphasALxEsyaB3De6K2t2H2bu2hyn4xhjPIAVgBe5ul8cfdo158kFmRwtKXc6jjHGzVkBeBE/P+HxcckcLCrjb4u3Oh3HGOPmrAC8TM+4ZvxsQDyvf7OTzXmFTscxxrgxKwAvdM/lXYgICeDhf6fjSdd6MsY0LisAL9QiLIi7L+/Cih0FfLQh1+k4xhg3ZQXgpX42IJ4ebZvyxMeZFJVWOB3HGOOGrAC8lL+f8Ni4HuQdLeHvS7Y5HccY44asALxY/4SW/LhfHC9/tYMd+cecjmOMcTNWAF7uvtFdCAnw55EPN9oOYWPM91gBeLnoiBBmXNaZpVvyWbxxn9NxjDFuxArAB9wwOIHOrcN57KONlJRXOh3HGOMmrAB8QKC/H49c1YM9h47zwn+2Ox3HGOMmrAB8xJAOrRjbqw0vfLmd3QeLnY5jjHEDVgA+5LdXdCPAT3j8441ORzHGuAErAB/SplkTfnVJJxZv3MdLS3fYFUON8XFWAD5myoWJ9ItvzhOfZJLy+8+Y/tYaPtu4j7KKKqejGWMaWYDTAUzjCg7wZ85tQ1i/5wjz1uzhww25fJyWS4vQQMb2asv4vrH0i2+OiDgd1RjTwMSTTg5KSUnR1NRUp2N4lfLKKr7ams+8tXv5NCOP0ooqEiJDGd8nlvF9Y0lqFeZ0RGPMeRKR1aqa8oPlVgDmhMKScham5zF/XQ7Ltx9EFfrGN2dC31iu6NmGyPBgpyMaY86BFYCpk9wjx/n3ur3MW5vDprxCAvyEizpHMaFfLJd2a01IoL/TEY0xtWQFYM5ZZu5R5q/NYf66HPYdLSU8OIDRyTFM6BvLoPaR+PnZ/gJj3JkVgDlvlVXKyh0Hmbc2hwXpeRwrraBNsxCu6tOWCX1j6RrT1OmIxphTOOcCEJF2wBtADFAFzFTVZ04acx1wn+uPx4DbVHW96747gKmAAC+p6t9cy/sALwIhQAXwC1VddaYsVgDu43hZJZ9l7mP+2hy+3JJPRZXSNSaCif1iuap3LDHNQpyOaIxxOZ8CaAO0UdU1IhIBrAbGq+rGGmOGAJmqekhERgOPqOpAEUkGZgMDgDJgIdXlsFVEPgWeVtUFIjIGuFdVLz5TFisA93TwWCkfbchl3toc1mUfRgSGdIhkQt84RiXHEB5sRxsb46TTFcBZ/2eqai6Q67pdKCKZQCywscaY5TVWWQHEuW53A1aoarErxJfABODPgAInthk0A/bW8TUZNxEZHsyNQxK5cUgiWQeKvttfcPd76/nd/DQu6x7DhL5tGdYpikB/O/fQGHdRp30AIpIILAWSVfXoacbcDXRV1VtEpBvwATAYOA58DqSq6q9c9y2ietOQHzBEVXed4vGmAdMA4uPj++/a9YMhxg2pKmt2H2b+2hw+3LCXw8XlRIYFcWXv6pPNesc1s5PNjGkk570TWETCgS+BJ1R17mnGjACeBy5U1YOuZTcD06neN7AROK6qvxaRZ4EvVXWOiEwCpqnqpWfKYJuAPFNZRRVfbsln/tocFmdWX3YiqVUYE/rGMuXCJNtEZEwDO68CEJFA4CNgkao+dZoxvYB5wGhV3XKaMX8A9qjq8yJyBGiuqirVvwoeUdUzHkZiBeD5jpaUsyCten/Bih0FDEhsyetTBtAkyM4rMKahnK4AzrpB1vXhPIvqnbyn+/CPB+YCk0/+8BeR6BpjJgJvu+7aC1zkun0JsLV2L8V4sqYhgVxzQTyzpw3m79f2JXVXAdP+mUpphc1UZkxjq81376HAZCBNRNa5lj0AxAOo6ovAQ0Ak8Lxru25FjbaZIyKRQDkwXVUPuZZPBZ4RkQCgBNd2fuM7xvZqS3FZJfe+v4Ff/mstz1/Xz3YSG9OI7EQw47jXl+/k4X9nMK5PW56a1Ad/O7PYmHp1zoeBGtPQbhySSFFZBX9euJnQIH/+MKGnHSFkTCOwAjBu4RcXd6S4tJK/L9lGk8AAHhzbzUrAmAZmBWDcxl2Xd6aorIJXlmURHuzPnZd3cTqSMV7NCsC4DRHhobHdOV5WybNfbCM0OIBbL+rgdCxjvJYVgHErIsITE3pSXFbJkws2ERbkz+TBiU7HMsYrWQEYt+PvJ/x1Um+Kyyp58IMMmgQFcHX/uLOvaIypEzvo2rilQH8//n5tX4Z1asW976/n4w25TkcyxutYARi3FRLozz8m96d/QgvumL2WLzbtczqSMV7FCsC4tdCgAGb9/AK6tWnKrW+uYfm2A05HMsZrWAEYt9c0JJA3pgwgKTKMW95IZfWuQ2dfyYOoKu+v3sOd76xj3to9HC0pdzqS8RF2KQjjMfYXljDpxW84WFTG21MHkRzbzOlI5233wWIemJfG19sOEBrkT3FZJUH+fgzr1IrRPdtwWbfWNAsNdDqm8XA2KbzxCjmHjzPpxW84Xl7JO9MG0al1hNORzklllfLqsiz++ukW/P2E+0Z35doB8azLPsyCtFwWpOeRc/g4AX7C0I6tGNMzhsu6x9AyLMjp6MYDWQEYr7HzQBE/+cc3CPDerYNJiAxzOlKdbM4r5N45G1iffZhLukbz+/HJtG3e5HtjVJUNe47wSXoun6Tlkl1wHH8/YXD7SEb3jGFkjxhahQc79AqMp7ECMF5lc14hP535DaFBAbx36+AffIC6o9KKSp5bsp0X/rONiJBAHr6yO1f1bnvWax6pKhl7j7IgPZdP0vLIOlCEn8CApJaM6dmGUT1iiG4a0kivwngiKwDjddL2HOHal1YQFRHMO/8zmKgI9/2NePWuQ/xmzga27j/G+D5teejKHue0OUdV2ZRXyIK0XD5Oy2V7fhEikJLQgtHJbRiVHOMRZWgalxWA8UqpOwuYPGsVCZGhzJ42iOah7rWNvKi0gr8s2szr3+ykTdMQnpjYkxFdouvt8bfuK+STtDwWpOeyKa8QgL7xzRmT3IbRPWOIaxFab89lPJcVgPFaX289wJTXvqVb26a8efMAIkLc46iZpVvyuX9uGjmHj3PD4ATuHdWV8OCGu/rK9vxjLEzP45O0XDL2HgWgd1wzRvdsw+jkGI/bV2LqjxWA8WqfbdzHrW+upl9CC16/ydlJ5g8Xl/H4R5nMWbOH9lFh/OnHvbggsWWjZth1sIgF6XksSMtl/Z4jAPRo25QxrjJoHxXeqHmMs6wAjNf7cP1ebp+9lmGdonjphv4EBzRuCagqH6fl8si/MzhcXM6tF3Xgl5d0JCTQuTICyC4oZlFG9TeDNbsPA9A1JoLRyW0Y0zPGYw+lNbVnBWB8wrvfZnPvnA2M7NGa567tR0AjTTKfd6SE381P57PMffSMbcafftyL7m2bNspz18Xew8dZmF69zyB11yFUoWN0OGOSYxjdsw1dYyJsJjYvZAVgfMary7J49MONjHdNMu/XgJPMV1Ups7/N5o+fZFJWWcVdl3dmytCkRiue87HvaMl33wxWZRVQpZDUKozbLu7ApJR2Tscz9cgmhTc+46ahSRSXVfKXRZtpEhTAHyYkN8hvtTsPFPGbuRtYsaOAwe0j+ePEniS28pwdra2bhnDD4ERuGJxIfmEpn27M418rd/O7eelc3CWK6Ag7t8DbWQEYrzR9REeKyyp4bsl2woL8+e0V9TfJfEVlFS9/ncXTi7cQFODHkxN7cs0F7Tx600lURDDXDUxgaIdWjPjrf3hj+S7uHmlzMns7KwDjte6+vAtFpZW8/HUWYcEB/Pqyzuf9mBl7j3DfnA2k5xzl8u6teXx8Mq296CzcxFZhjOwewz9X7OIXIzoQGmQfEd7M/naN1zoxyXxxWQXPfL6V0CB//uccJ5kvKa/k2c+38o+lO2gRGsjz1/VjdHKMR//WfzpThyexMCOP91L3cOOQRKfjmAZkBWC8mp+f8MeJvSguq+SPCzYReg6TzK/KKuA3czaw40ARV/eP43dXdHO7M47rU/+ElvSLb86sr7O4flAC/g24E904y/0PVTDmPPn7CU9f04dLu0Xz4AcZzFm9p1brFZaU8+D8dCb94xvKKqt4Y8oA/vcnvb36w/+EqcPas7ugmE8z8pyOYhqQFYDxCdWTzPdjaMdI7nl/PQvSzjzJ/Beb9nH500t5c+UupgxNYtGM4QzvHNVIaZ13eY8Y4luGMvOrHU5HMQ3ICsD4jJBAf166IYV+8S24ffZalmza/4MxB4+Vcvvba5nyWioRIQHMuW0ID13ZnbAGvIaPO/L3E24ZlsTa3YdZvavA6TimgVgBGJ8SGhTAKzddQJeYCG59czXLt1dPMq+qzF+bw6VPfcmC9FxmXNqJj341jH7xLRxO7Jyr+8fRrEkgM5fatwBvddYCEJF2IrJERDJFJENE7jjFmOtEZIPrZ7mI9K5x3x0iku5ad8ZJ6/1KRDa77vtz/bwkY86sepL5gSREhnLL66ksSMtlymvfMuOddSREhvHx7cOYcWlnggJ8+/ej0KAAJg9K4NON+8g6UOR0HNMAavMvvAK4S1W7AYOA6SLS/aQxWcBFqtoLeByYCSAiycBUYADQGxgrIp1c940AxgG9VLUH8L/18HqMqZWWYUG8efNAoiOCue2tNazYUcCDY7sz57YhdLaLo33nhiEJBPr58crXWU5HMQ3grAWgqrmqusZ1uxDIBGJPGrNcVQ+5/rgCiHPd7gasUNViVa0AvgQmuO67DXhSVUtdj/HDDbLGNKDopiG8NXUQ/3NRez799XBuvjDJDnk8SXRECOP7tuW91dkUFJU5HcfUszp9xxWRRKAvsPIMw24GFrhupwPDRSRSREKBMcCJq0x1BoaJyEoR+VJELjjNc04TkVQRSc3Pz69LXGPOKrZ5E+4f3Y12LW3mrNO5ZVh7SsqreHPFLqejmHpW6wIQkXBgDjBDVY+eZswIqgvgPgBVzQT+BCwGFgLrqd6kBNUnobWgerPSPcC7corTKlV1pqqmqGpKVJTvHIZnjLvo3DqCEV2ieOObnZSUVzodx9SjWhWAiARS/eH/lqrOPc2YXsDLwDhVPXhiuarOUtV+qjocKAC2uu7aA8zVaquAKqDVub8UY0xDmTqsPQeOlTF/bY7TUUw9qs1RQALMAjJV9anTjIkH5gKTVXXLSfdF1xgzEXjbddd84BLXfZ2BIODAub0MY0xDGtwhkh5tm/LSVzuoqvKcOUTMmdXmG8BQYDJwiYisc/2MEZFbReRW15iHgEjgedf9NWdtmSMiG4EPgek1dha/ArQXkXRgNnCjetLsNMb4EBFh6rD2bM8v4j9b7HgNb2EzghljaqW8sorhf15CQmQos6cNdjqOqYPTzQjm22e6GGNqLdDfjylDk1ixo4C0PUecjmPqgRWAMabWrhnQjvDgAF6yi8R5BSsAY0ytNQ0J5GcD2vFxWi45h487HcecJysAY0yd3DQ0CQFetctDeDwrAGNMnbRt3oQrerXh7VW7OXK83Ok45jxYARhj6mzqsPYUlVUye9Vup6OY82AFYIyps+TYZgzpEMmry3ZSVlHldBxzjqwAjDHnZOqw9uQdLeHjtL1ORzHnyArAGHNOLuocRafocGYuzcKTTig1/2UFYIw5J36ueYMzc4+yfPvBs69g3I4VgDHmnI3rE0ur8GCbN9hDWQEYY85ZSKA/Px+SwJdb8tmcV+h0HFNHVgDGmPNy3cAEQgL9eNkuD+FxrACMMeelRVgQk1LaMX9dDvuPljgdx9SBFYAx5rzdfGESFVXK69/sdDqKqQMrAGPMeUuIDGNk9xjeXLGbotKKs69g3IIVgDGmXkwd3p4jx8t5LzXb6SimlqwAjDH1on9CC/ontGDWsiwqbd5gj2AFYIypN1OHJZFdcJxFGXlORzG1YAVgjKk3l3WPISEylJlLd9jlITyAFYAxpt74+wk3X5jEuuzDrN51yOk45iysAIwx9erq/nE0Dw20y0N4ACsAY0y9Cg0KYPKgBBZn7iPrQJHTccwZWAEYY+rd5MEJBPr5Metr+xbgzqwAjDH1LjoihAl9Y3kvdQ8Hj5U6HcechhWAMaZB3DIsidKKKt5cYfMGuysrAGNMg+jUOoIRXaJ445udlJRXOh3HnIIVgDGmwUwd3p6DRWXMW5vjdBRzClYAxpgGM7h9JMmxTXnpqx1U2eUh3I4VgDGmwYgIU4e1Z0d+EUs273c6jjnJWQtARNqJyBIRyRSRDBG54xRjrhORDa6f5SLSu8Z9d4hIumvdGadY924RURFpdf4vxxjjbsb0bEPbZiF2Ypgbqs03gArgLlXtBgwCpotI95PGZAEXqWov4HFgJoCIJANTgQFAb2CsiHQ6sZKItAMuA+wwAWO8VKC/HzcNTWJlVgEb9hx2Oo7Hqais4qWlOyguq/95Fs5aAKqaq6prXLcLgUwg9qQxy1X1xIU/VgBxrtvdgBWqWqyqFcCXwIQaqz4N3AvYxkFjvNhPB7QjIjiAl77KcjqKx3lt+U6e+CSTpVsO1Ptj12kfgIgkAn2BlWcYdjOwwHU7HRguIpEiEgqMAdq5HusqIEdV19cxszHGw0SEBPKzgfF8kpbLnkPFTsfxGNkFxfz10y38qGs0I3u0rvfHr3UBiEg4MAeYoapHTzNmBNUFcB+AqmYCfwIWAwuB9UCFqwx+CzxUi+edJiKpIpKan59f27jGGDfz8yGJCPDqsp1OR/EIqsqDH6QjAo+NT0ZE6v05alUAIhJI9Yf/W6o69zRjegEvA+NU9eCJ5ao6S1X7qepwoADYCnQAkoD1IrKT6k1Ga0Qk5uTHVdWZqpqiqilRUVF1e3XGGLfRtnkTxvZqw+xVuzlyvNzpOG7vow25/GdzPndd3oXY5k0a5DlqcxSQALOATFV96jRj4oG5wGRV3XLSfdE1xkwE3lbVNFWNVtVEVU0E9gD9VNWmETLGi90yrD1FZZW8vcqO+ziTI8XlPPphBr3imvHzIYkN9jwBtRgzFJgMpInIOteyB4B4AFV9kepNOZHA866vKRWqmuIaO0dEIoFyYHqNncXGGB+THNuMIR0ieW3ZTqYMTSIowE5FOpUnF2ZyqLic124agL9f/W/6OeGsBaCqXwNnTKCqtwC3nOa+YbV4jsSzjTHGeIepw9tz06vf8tGGvUzsF3f2FXzMyh0HeXtVNtOGtyc5tlmDPpfVrzGmUV3cOYpO0eE2b/AplFZUcv+8NOJaNGHGpZ3OvsJ5sgIwxjSqE5eH2JRXyLJtB8++gg954T/b2ZFfxO/HJxMaVJst9OfHCsAY0+jG9W1Lq/BgZn5ll4c4Ydv+Qp5fsp2rerfl4i7RjfKcVgDGmEYXHODPz4cksHRLPpvyTnlakU+pqlIemJtOkyB/Hhx78pV2Go4VgDHGEdcNTKBJoD8v2+UheDc1m1U7C/jtmG5ERQQ32vNaARhjHNEiLIhJKXF8sC6HfUdLnI7jmP2FJfzhk0wGJrXkJymNe1SUFYAxxjFTLkyiokp5bflOp6M45rEPN1JSXsUfJvZskMs9nIkVgDHGMQmRYYzqEcNbK3ZRVFr/lzt2d0s27eejDbn88pKOdIgKb/TntwIwxjhq6vD2HC2p4N3UbKejNKqi0gp+Nz+djtHh3HpRB0cyWAEYYxzVL74F/RNa8MqyLCoqq5yO02ieXryFnMPH+ePEno5dEsMKwBjjuKnD2pNdcJxFGfucjtIo0nOO8MqyLK4dGM8FiS0dy2EFYIxx3GXdW5MQGcrMr7z/8hAVlVX8Zu4GIsODuW9UV0ezWAEYYxzn7yfccmES67MPk7rLuy8Y/NrynaTnHOWRK3vQrEmgo1msAIwxbuHq/u1oERrIzKXee3mImlM8jun5g/mvGp0VgDHGLTQJ8uf6QQl8lrmPHfnHnI5T7xpjise6sgIwxriNGwYnEujnx6yvve/yEI0xxWNdWQEYY9xGVEQwE/vF8v7qPRw8Vup0nHpTPcXjxgaf4rGurACMMW7llmFJlFZU8eznW73miKDqKR7L+MOEng06xWNdWQEYY9xKx+gIrh0Yz+vf7OKe9zdQVuHZJ4etyirg7VXZ3HxhUoNP8VhXDT/ljDHG1NET45NpFR7Ms59vJefQcV68vj/NQp09ZPJclFZUcv/cDY02xWNd2TcAY4zbERHuvKwzT03qTequAia8sIxdB4ucjlVnL/xnO9sbcYrHurICMMa4rYn94njz5oEUFJUx/rllpO4scDpSrW3bf6zRp3isKysAY4xbG9g+knm/GErz0CCufWklH6zLcTrSWVVP8ZhGSKBfo07xWFdWAMYYt5fUKoy5tw2hT3xz7pi9jmc+c+8jhL6b4vGKxp3isVsvtyEAAAjGSURBVK6sAIwxHqFFWBD/vHkAE/rG8vRnW7jr3fWUVlQ6HesH8gtLv5vicVJKO6fjnJH77ZUwxpjTCA7w56lJvUlqFcZTi7ew5/Bx/nF9f1qEBTkd7TuPfeTcFI91Zd8AjDEeRUS4/UedeOanfVi3+zATX1hO1gH3OEJoyeb9fLh+L9NHODPFY11ZARhjPNK4PrH8a+pAjhwvZ8Lzy1i546CjeYrLKvjdPNcUjxe3dzRLbVkBGGM8VkpiS+b9Yggtw4K4ftZK5q7Z41iWmlM8Bgf4O5ajLqwAjDEeLSEyjHm3DaV/QgvufHc9Ty3e0uhHCKXnHGHW11n8bICzUzzWlRWAMcbjNQsN5I0pA7m6fxzPfr6VGe+so6S8cY4Qqqis4v65aUSGB/Ob0c5O8VhXZy0AEWknIktEJFNEMkTkjlOMuU5ENrh+lotI7xr33SEi6a51Z9RY/hcR2eRaZ56INK+/l2WM8TVBAX785epe3DOyCx+s28v1L69slEtKv7Z8J2k5R3j4yu6OT/FYV7X5BlAB3KWq3YBBwHQROfnUtizgIlXtBTwOzAQQkWRgKjAA6A2MFZETV0RaDCS71tkC3H++L8YY49tEhOkjOvJ/P+vLhpwjTHh+OdsbcHaxPYeqp3i8pGs0V/Rs02DP01DOWgCqmquqa1y3C4FMIPakMctV9cRMziuAONftbsAKVS1W1QrgS2CCa51PXctOXscYY87Llb3b8vbUQRSVVjDhuWUs336g3p9DVXnog4zqKR7H9XD7Y/5PpU77AEQkEegLrDzDsJuBBa7b6cBwEYkUkVBgDHCqU+Om1Fjn5OecJiKpIpKan59fl7jGGB/WP6EF86cPJbppCDfMWsV7qdn1+vgfp+Xyxab93HlZZ+JahNbrYzeWWheAiIQDc4AZqnr0NGNGUF0A9wGoaibwJ6o39ywE1lO9SanmOr91LXvrVI+pqjNVNUVVU6Kiomob1xhjaNcylDm3DWFg+5bc8/4G/rJoE1VV53+E0JHich7590Z6xrrXFI91VasCEJFAqj/831LVuacZ0wt4GRinqt+dkaGqs1S1n6oOBwqArTXWuREYC1yn7nxlJ2OMx2rWJJDXbhrANSnteG7Jdm6fvfa8jxB6cuEmDhWX8ceJPQnw99yDKc96LSCp3rA1C8hU1adOMyYemAtMVtUtJ90Xrar7XWMmAoNdy0dR/U3hIlUtPr+XYYwxpxfo78eTP+5JUlQYTy7YRM7h47x0Qwqtwut+pc7qKR53M3WY+03xWFdytl+8ReRC4CsgDTgxOecDQDyAqr4oIi8DPwZ2ue6vUNUU1/pfAZFAOXCnqn7uWr4NCAZOfFtYoaq3nilLSkqKpqam1ukFGmNMTQvScpnxzjqimwbz6s8voGN0RK3XLa2oZMwzX1FSXsXiO4e75SxfpyIiq098Jn9vuSdtebECMMbUh3XZh7nl9VRKKyp58fr+DO3YqlbrPfPZVp7+bAuv3nQBI9x0lq9TOV0BeO7GK2OMOUd92jVn/vQhtGkWwo2vrGL2qt1nXWfb/mM8t2QbV/Zu61Ef/mdiBWCM8UlxLUJ5/7YhDO4QyW/mpvHkgtMfIVRVpTwwr3qKx4fceIrHurICMMb4rKYhgbz68wu4dmA8L365nen/WsPxsh8eIfTe6mxWZbn/FI91ZQVgjPFpAf5+PDE+md+O6cbCjDx++tIK9heWfHd/fmEpT3ycyQAPmOKxrqwAjDE+T0SYOrw9L17fny15hUx4bjmb8wqBGlM8TnD/KR7rygrAGGNcRvaI4d3/GUxZZRVXv7Ccv366+bspHjtGu/8Uj3VlBWCMMTX0jGvG/OlDiW3RhP/7YhsdosI8ZorHuvKMsxiMMaYRxTZvwnu3DubvX2xjXJ9Yj5nisa6sAIwx5hQiQgK5f0w3p2M0KNsEZIwxPsoKwBhjfJQVgDHG+CgrAGOM8VFWAMYY46OsAIwxxkdZARhjjI+yAjDGGB/lUTOCiUg+/512sq5aAQfqMY6ns/fjv+y9+D57P77PG96PBFWNOnmhRxXA+RCR1FNNiear7P34L3svvs/ej+/z5vfDNgEZY4yPsgIwxhgf5UsFMNPpAG7G3o//svfi++z9+D6vfT98Zh+AMcaY7/OlbwDGGGNqsAIwxhgf5RMFICKjRGSziGwTkd84nccpItJORJaISKaIZIjIHU5ncgci4i8ia0XkI6ezOE1EmovI+yKyyfXvZLDTmZwiIr92/T9JF5G3RSTE6Uz1zesLQET8geeA0UB34Gci0t3ZVI6pAO5S1W7AIGC6D78XNd0BZDodwk08AyxU1a5Ab3z0fRGRWOB2IEVVkwF/4KfOpqp/Xl8AwABgm6ruUNUyYDYwzuFMjlDVXFVd47pdSPV/7lhnUzlLROKAK4CXnc7iNBFpCgwHZgGoapmqHnY2laMCgCYiEgCEAnsdzlPvfKEAYoHsGn/eg49/6AGISCLQF1jpbBLH/Q24F6hyOogbaA/kA6+6Nom9LCJhTodygqrmAP8L7AZygSOq+qmzqeqfLxSAnGKZTx/7KiLhwBxghqoedTqPU0RkLLBfVVc7ncVNBAD9gBdUtS9QBPjkPjMRaUH1loIkoC0QJiLXO5uq/vlCAewB2tX4cxxe+FWutkQkkOoP/7dUda7TeRw2FLhKRHZSvWnwEhF509lIjtoD7FHVE98K36e6EHzRpUCWquarajkwFxjicKZ65wsF8C3QSUSSRCSI6h05/3Y4kyNERKjevpupqk85ncdpqnq/qsapaiLV/y6+UFWv+y2vtlQ1D8gWkS6uRT8CNjoYyUm7gUEiEur6f/MjvHCHeIDTARqaqlaIyC+BRVTvyX9FVTMcjuWUocBkIE1E1rmWPaCqnziYybiXXwFvuX5Z2gHc5HAeR6jqShF5H1hD9dFza/HCS0LYpSCMMcZH+cImIGOMMadgBWCMMT7KCsAYY3yUFYAxxvgoKwBjjPFRVgDGGOOjrACMMcZH/T/mYC0msc/L5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the loss history!\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.149\n",
      "Accuracy after training for 100 epochs:  0.22\n"
     ]
    }
   ],
   "source": [
    "# Let's check how it performs on validation set\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Now, let's train more and see if it performs better\n",
    "classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-3, batch_size=300, reg=1e1)\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy after training for 100 epochs: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.244\n",
      "0.242\n",
      "0.241\n",
      "0.245\n",
      "best validation accuracy achieved: 0.245000\n",
      "best learning rates: 0.010000\n",
      "best reg strengths: 0.001000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 300\n",
    "\n",
    "learning_rates = [1e-1, 1e-2]\n",
    "reg_strengths = [1e-2, 1e-3]\n",
    "\n",
    "#best_classifier = None\n",
    "#best_val_accuracy = None\n",
    "\n",
    "best_classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "best_classifier.fit(train_X, train_y, batch_size, learning_rates[0], reg_strengths[0], num_epochs)\n",
    "pred = best_classifier.predict(val_X)\n",
    "best_val_accuracy = multiclass_accuracy(pred, val_y)\n",
    "\n",
    "for i in learning_rates:\n",
    "    for j in reg_strengths:\n",
    "        classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "        classifier.fit(train_X, train_y, batch_size, i, j, num_epochs)\n",
    "        pred = classifier.predict(val_X)\n",
    "        accuracy = multiclass_accuracy(pred, val_y)\n",
    "        print(accuracy)\n",
    "        if accuracy > best_val_accuracy:\n",
    "            best_classifier = classifier\n",
    "            best_val_accuracy = accuracy\n",
    "            best_learning_rates = i\n",
    "            best_reg_strengths = j\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)\n",
    "print('best learning rates: %f' % best_learning_rates)\n",
    "print('best reg strengths: %f' % best_reg_strengths)\n",
    "\n",
    "best_classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "best_classifier.fit(train_X, train_y, batch_size, best_learning_rates, best_reg_strengths, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear softmax classifier test set accuracy: 0.204000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Linear softmax classifier test set accuracy: %f' % (test_accuracy, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
